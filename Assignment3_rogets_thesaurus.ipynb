{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the functions that are going to be used to retrieve the words and their synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to clean and extract the word\n",
    "def extract_word(entry):\n",
    "    parts = entry.split('N.')\n",
    "    if parts and len(parts) > 1:\n",
    "        word = parts[0].strip()\n",
    "        #when word has [] remove them and everything inside\n",
    "        while '[' in word and ']' in word:\n",
    "            start = word.find('[')\n",
    "            end = word.find(']') + 1\n",
    "            if start < end:\n",
    "                word = word[:start] + word[end:]\n",
    "            else:\n",
    "                break  # In case of mismatched brackets, prevent infinite loop\n",
    "        word = ''.join(e for e in word if e.isalpha() or e.isspace())\n",
    "        \n",
    "        #if word has \"  \" do it as \" \"\n",
    "        if \"  \" in word:\n",
    "            word = word.replace(\"  \", \" \")\n",
    "            \n",
    "        #if word starts with a space, remove it\n",
    "        if word[0] == \" \":\n",
    "            word = word[1:]\n",
    "            \n",
    "        #if word ends with a space, remove it\n",
    "        if word[-1] == \" \":\n",
    "            word = word[:-1]\n",
    "            \n",
    "        #if word starts with lowercase, capitalize it\n",
    "        if word[0].islower():\n",
    "            word = word.capitalize()\n",
    "        \n",
    "        # Delete everything before the first Capital letter\n",
    "        for i in range(len(word)):\n",
    "            if word[i].isupper():\n",
    "                word = word[i:]\n",
    "                break\n",
    "        if '\\r\\n' in word:\n",
    "            word = word.split('\\r\\n')[1]\n",
    "        return word\n",
    "    return None\n",
    "\n",
    "def extract_synonyms(entry):\n",
    "    parts = entry.split('N.')\n",
    "    \n",
    "    #take after the N. and remove the \\r\\n\n",
    "    if parts and len(parts) > 1:\n",
    "        synonyms = parts[1].split('â€”')\n",
    "        if synonyms and len(synonyms) > 1:\n",
    "            synonyms = synonyms[1].split(',' or ';')\n",
    "            synonyms = [syn.strip() for syn in synonyms if syn.strip()]\n",
    "        #remove any \"V.\" or \"&c.\" or number\n",
    "        for i in range(len(synonyms)):\n",
    "            if \"adj.\" in synonyms[i]:\n",
    "                synonyms[i] = synonyms[i].replace(\"adj.\", \"\")\n",
    "            if \"Adj.\" in synonyms[i]:\n",
    "                synonyms[i] = synonyms[i].replace(\"Adj.\", \"\")\n",
    "            if \"V.\" in synonyms[i]:\n",
    "                synonyms[i] = synonyms[i].replace(\"V.\", \"\")\n",
    "            if \"&c.\" in synonyms[i]:\n",
    "                synonyms[i] = synonyms[i].replace(\"&c.\", \"\")\n",
    "            if \"v.\" in synonyms[i]:\n",
    "                synonyms[i] = synonyms[i].replace(\"v.\", \"\")\n",
    "            #if synonym has a number remove it\n",
    "            if any(char.isdigit() for char in synonyms[i]):\n",
    "                synonyms[i] = ''.join(e for e in synonyms[i] if not e.isdigit())\n",
    "            \n",
    "        #when synonym has [] remove them and everything inside\n",
    "        for i in range(len(synonyms)):\n",
    "            while '[' in synonyms[i] and ']' in synonyms[i]:\n",
    "                start = synonyms[i].find('[')\n",
    "                end = synonyms[i].find(']') + 1\n",
    "                if start < end:\n",
    "                    synonyms[i] = synonyms[i][:start] + synonyms[i][end:]\n",
    "                else:\n",
    "                    break\n",
    "                \n",
    "        #when synonym has {} remove them and everything inside\n",
    "        for i in range(len(synonyms)):\n",
    "            while '{' in synonyms[i] and '}' in synonyms[i]:\n",
    "                start = synonyms[i].find('{')\n",
    "                end = synonyms[i].find('}') + 1\n",
    "                if start < end:\n",
    "                    synonyms[i] = synonyms[i][:start] + synonyms[i][end:]\n",
    "                else:\n",
    "                    break\n",
    "        \n",
    "        #if there is \"\\r\\n\" replace it with a \" \"\n",
    "        for i in range(len(synonyms)):\n",
    "            if '\\r\\n' in synonyms[i]:\n",
    "                synonyms[i] = synonyms[i].replace('\\r\\n', ' ')\n",
    "                              \n",
    "    return synonyms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing all the necessities like BeautifulSoup, url path etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of Roget's Thesaurus Classification\n",
    "url = 'https://www.gutenberg.org/cache/epub/22/pg22-images.html'\n",
    "\n",
    "# Download page content\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()  # This will raise an error if the download failed\n",
    "\n",
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "thesaurus = {}\n",
    "current_h2, current_h3, current_h4, current_h5 = None, None, None, None\n",
    "start_processing = False  # Flag to start processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Itterating for between each class, subclass, category, subcategory and finding the words and their synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag in soup.find_all(['h2', 'h3', 'h4', 'h5', 'p']):\n",
    "    if tag.name == 'h2':\n",
    "        current_h2 = tag.get_text(strip=True).split('\\n')[0]\n",
    "        # Check if the current class is \"CLASS IWORDS EXPRESSING ABSTRACT RELATIONS\" or later\n",
    "        if \"CLASS IWORDS EXPRESSING ABSTRACT RELATIONS\" in current_h2:\n",
    "            start_processing = True\n",
    "        if not start_processing:\n",
    "            continue  # Skip all processing until the flag is True\n",
    "        thesaurus[current_h2] = {}\n",
    "        current_h3 = current_h4 = current_h5 = None\n",
    "    elif start_processing:  # Only process other tags if start_processing is True\n",
    "        if tag.name == 'h3':\n",
    "            current_h3 = tag.get_text(strip=True)\n",
    "            thesaurus[current_h2][current_h3] = {}\n",
    "            current_h4 = current_h5 = None\n",
    "        elif tag.name == 'h4' and current_h3:\n",
    "            current_h4 = tag.get_text(strip=True)\n",
    "            thesaurus[current_h2][current_h3][current_h4] = {}\n",
    "            current_h5 = None\n",
    "        elif tag.name == 'h5' and current_h4:\n",
    "            current_h5 = tag.get_text(strip=True)\n",
    "            thesaurus[current_h2][current_h3][current_h4][current_h5] = {}\n",
    "        elif tag.name == 'p' and 'p2' in tag.get('class', []):\n",
    "            word = extract_word(tag.text)\n",
    "            if word:\n",
    "                if current_h5 is not None:\n",
    "                    thesaurus[current_h2][current_h3][current_h4][current_h5][word] = extract_synonyms(tag.text)\n",
    "                elif current_h4 is not None:\n",
    "                    thesaurus[current_h2][current_h3][current_h4][word] = extract_synonyms(tag.text)\n",
    "                elif current_h3 is not None:\n",
    "                    thesaurus[current_h2][current_h3][word] = extract_synonyms(tag.text)\n",
    "                elif current_h2 is not None:\n",
    "                    thesaurus[current_h2][word] = extract_synonyms(tag.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the dictionary into a json format file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thesaurus hierarchy saved to rogets_thesaurus_hierarchy.json\n"
     ]
    }
   ],
   "source": [
    "# Save the hierarchy to a JSON file\n",
    "json_filename = 'rogets_thesaurus_hierarchy.json'\n",
    "with open(json_filename, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(thesaurus, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Thesaurus hierarchy saved to {json_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
